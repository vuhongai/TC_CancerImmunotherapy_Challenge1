{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\" \n",
    "\n",
    "import numpy as np\n",
    "import anndata as ad\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from keras.layers import Input, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from utils import regression_model\n",
    "\n",
    "np.random.seed(1024) \n",
    "random.seed(2048)\n",
    "tf.random.set_seed(1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_size = 32"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leave 3 genes 'Rps6', 'Zfp292', 'Prdm1' for validation of model performance in step 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop = pd.read_csv(\"data/training_cell_state_proportions.csv\", index_col=0)\n",
    "prop = prop.drop(index=['Rps6', 'Zfp292', 'Prdm1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_embed = np.load(f'submission/embedding/gene_embedding_{emb_size}.npy')\n",
    "g_name = np.load(f'submission/embedding/gene_names_{emb_size}.npy', allow_pickle= True)\n",
    "\n",
    "genes = list(set(prop.index.tolist()))\n",
    "training_conditions = [g for g in genes if g in g_name]\n",
    "\n",
    "#extract embedding of training set\n",
    "X, Y = [], []\n",
    "for g in training_conditions:\n",
    "    x = g_embed[list(g_name).index(g)]\n",
    "    y = np.array(prop.loc[g].values)\n",
    "    X.append(x)\n",
    "    Y.append(y)\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train different model to map 32D gene embedding vector to 5D output vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler on the whole gene list\n",
    "X_scaler = StandardScaler()\n",
    "X_scaler.fit(g_embed)\n",
    "\n",
    "with open(f'./submission/scaler_{emb_size}.pkl', 'wb') as f:\n",
    "    pickle.dump(X_scaler, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=2000\n",
    "\n",
    "X, Y = shuffle(X,Y,random_state=36)\n",
    "kf = KFold(n_splits=10)\n",
    "kfold = kf.split(X, Y)\n",
    "\n",
    "for n_try in range(8):\n",
    "\n",
    "    score = []\n",
    "    predictions = []\n",
    "\n",
    "    for k, (train, val) in enumerate(kfold):\n",
    "        X_train, Y_train = X[train], Y[train]\n",
    "        X_val, Y_val = X[val], Y[val]\n",
    "\n",
    "        X_train_transformed = X_scaler.transform(X_train)\n",
    "        X_val_transformed = X_scaler.transform(X_val)\n",
    "\n",
    "        for dropout_rate in [0]:\n",
    "            for l1 in [1e-3, 1e-4,0]:\n",
    "                for l2 in [0, 1e-5]:\n",
    "                    for learning_rate in [1e-3]:\n",
    "\n",
    "                        #define lr schedule\n",
    "                        decay = learning_rate / (epochs-50) * 10                        \n",
    "                        def scheduler(epoch, lr):\n",
    "                            if epoch < 50:\n",
    "                                return lr\n",
    "                            else:\n",
    "                                return lr * 1/(1+decay*epoch) #tf.math.exp(-0.1)\n",
    "\n",
    "                        for mae_weight in [2]:\n",
    "                            for batch_size in [8,16]:\n",
    "                                model_path = f\"./submission/checkpoints/NN/model_{emb_size}_{dropout_rate}_{l1}_{l2}_{learning_rate}_{mae_weight}_{batch_size}_{k}_{n_try}.h5\"\n",
    "\n",
    "                                #define model\n",
    "                                model = regression_model(\n",
    "                                            input_size = emb_size,\n",
    "                                            output_size = 5,\n",
    "                                            size_dense = 8,\n",
    "                                            dropout_rate = dropout_rate,\n",
    "                                            l1 = l1,\n",
    "                                            l2 = l2,\n",
    "                                            learning_rate = learning_rate,\n",
    "                                            mae_weight=mae_weight\n",
    "                                        )\n",
    "\n",
    "                                #define callbacks\n",
    "                                checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "                                    model_path,\n",
    "                                    monitor='val_mae', \n",
    "                                    verbose=0, save_best_only=True, mode='min'\n",
    "                                )\n",
    "                                early_stop = keras.callbacks.EarlyStopping(monitor='val_mae', patience=200, mode='min')\n",
    "                                schedule = keras.callbacks.LearningRateScheduler(scheduler, verbose=0)\n",
    "\n",
    "                                # training\n",
    "                                model.fit(X_train_transformed, Y_train, \n",
    "                                            # sample_weight=w, \n",
    "                                            epochs=epochs, \n",
    "                                            shuffle=True, \n",
    "                                            batch_size=batch_size,\n",
    "                                            validation_data=(X_val_transformed,Y_val),\n",
    "                                            callbacks = [checkpoint, early_stop, schedule],\n",
    "                                            verbose = 0\n",
    "                                            )\n",
    "\n",
    "                                # calculate best val_mae\n",
    "                                model.load_weights(model_path)\n",
    "                                mae_train = mean_absolute_error(Y_train, model.predict(X_train_transformed))\n",
    "                                mae_val = mean_absolute_error(Y_val, model.predict(X_val_transformed))\n",
    "\n",
    "\n",
    "                                score.append([\n",
    "                                    n_try, k, dropout_rate, l1, l2, learning_rate, mae_weight, batch_size, mae_train, mae_val\n",
    "                                ])\n",
    "\n",
    "                                print(n_try, k, dropout_rate, l1, l2, learning_rate, mae_weight, batch_size, mae_train, mae_val)\n",
    "\n",
    "                                del model, model_path\n",
    "\n",
    "\n",
    "    score = pd.DataFrame(\n",
    "        score,\n",
    "        columns = [\"n_try\", \"k\", \"dropout_rate\", \"l1\", \"l2\", \"learning_rate\", \"mae_weight\", \"batch_size\", \"mae_train\", \"mae_val\"]\n",
    "    )\n",
    "    score.to_csv(f\"./submission/predictions/NN_{emb_size}_score_try{n_try}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "eeb8680eb43b9a87a49e32cc1c39b4f8c04117cd7cf42ba09bd4997cc8bf2498"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
